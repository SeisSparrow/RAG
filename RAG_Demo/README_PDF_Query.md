# ğŸ“„ PDF Query System - RAG Framework

This guide shows you how to use the RAG (Retrieval Augmented Generation) framework to query PDF documents, specifically using the example file `test_pdf/xingshisusongfa.pdf`.

## ğŸ¯ Overview

The PDF Query System allows you to:
- Process PDF documents and extract text content
- **Extract and analyze images from PDFs**
- **Extract and query tables from PDFs**
- Create embeddings for semantic search
- Query documents using natural language
- Get precise answers with source references
- Use advanced techniques like hybrid search and reranking

## ğŸ—ï¸ System Architecture

```
PDF Document â†’ Text/Image/Table Extraction â†’ Chunking â†’ Embeddings â†’ Vector Database â†’ Query Processing â†’ Response
```

### Multi-Modal Processing Pipeline
- **Text**: Direct extraction and chunking
- **Images**: Extract â†’ Visual Analysis â†’ Context Augmentation â†’ Text Description
- **Tables**: Extract â†’ Markdown Conversion â†’ Context Augmentation â†’ Structured Description

## ğŸ“‹ Prerequisites

### 1. Environment Setup
```bash
# Navigate to the project directory
cd /Users/zhennan/Documents/GithubRepos/RAG/RAG_Demo

# Activate virtual environment
source venv/bin/activate

# Install dependencies (if not already done)
pip install -r requirements.txt
```

### 2. Required Services
- **Elasticsearch**: Running on `localhost:9200`
- **Embedding Service**: Configured in `config.py`
- **Reranking Service**: Optional, for improved results

## ğŸš€ Quick Start

### Step 1: Create Elasticsearch Index
```bash
python3 -c "from es_functions import create_elastic_index; create_elastic_index('pdf_index')"
```

### Step 2: Process PDF Document
```bash
# Process the example PDF file (text content)
python3 -c "
from document_process import process_pdf
process_pdf('pdf_index', 'test_pdf/xingshisusongfa.pdf')
"

# Extract and process images from PDF
python3 -c "
from image_table import extract_images_from_pdf
results = extract_images_from_pdf('test_pdf/image_extraction_example.pdf')
print(f'Extracted {len(results)} images')
"

# Extract and process tables from PDF
python3 -c "
from image_table import extract_tables_from_pdf
results = extract_tables_from_pdf('test_pdf/table_extraction_example.pdf')
print(f'Extracted {len(results)} tables')
"
```

### Step 3: Query the Document
```bash
python3 -c "
from retrieve_documents import elastic_search, rerank
query = 'ä»€ä¹ˆæ˜¯åˆ‘äº‹è¯‰è®¼æ³•çš„åŸºæœ¬åŸåˆ™ï¼Ÿ'
results = elastic_search(query, 'pdf_index')
print('Search Results:')
for i, result in enumerate(results[:3]):
    print(f'{i+1}. {result[\"text\"][:200]}...')
"
```

## ğŸ“– Detailed Usage

### 1. Document Processing

The `document_process.py` module handles PDF text processing:

```python
from document_process import process_pdf

# Process a PDF file
process_pdf(
    es_index='pdf_index',           # Elasticsearch index name
    file_path='test_pdf/xingshisusongfa.pdf'  # Path to PDF file
)
```

**What happens during processing:**
- PDF text extraction using PyMuPDF
- Text chunking (1024 tokens per chunk, 100 token overlap)
- Embedding generation for each chunk
- Storage in Elasticsearch with metadata

### 2. Image Processing

The `image_table.py` module handles image extraction and analysis:

```python
from image_table import extract_images_from_pdf, summarize_image, context_augmentation

# Extract images from PDF
results = extract_images_from_pdf('test_pdf/image_extraction_example.pdf')

# Process individual image
image_summary = summarize_image('path/to/image.png')

# Augment image description with context
augmented_description = context_augmentation(page_context, image_description)
```

**Image Processing Pipeline:**
- **Extraction**: Extract images from PDF pages
- **Filtering**: Remove small/background images
- **Analysis**: Use vision model to describe image content
- **Context Augmentation**: Enhance description using surrounding text
- **Storage**: Store descriptions with page references

**Example Image Processing:**
```python
# Extract all images from a PDF
pdf_path = 'test_pdf/image_extraction_example.pdf'
image_results = extract_images_from_pdf(pdf_path)

for result in image_results:
    print(f"Page {result['page_num'] + 1}, Image {result['image_index']}")
    print(f"Description: {result['summary']}")
    print(f"Context Augmented: {result['context_augmented_summary']}")
    print("-" * 50)
```

### 3. Table Processing

The `image_table.py` module also handles table extraction and analysis:

```python
from image_table import extract_tables_from_pdf, table_context_augmentation

# Extract tables from PDF
results = extract_tables_from_pdf('test_pdf/table_extraction_example.pdf')

# Process individual table
table_description = table_context_augmentation(page_context, table_markdown)
```

**Table Processing Pipeline:**
- **Detection**: Find tables in PDF pages
- **Extraction**: Convert tables to Markdown format
- **Context Analysis**: Analyze surrounding text for context
- **Description Generation**: Create natural language descriptions
- **Storage**: Store structured table data with descriptions

**Example Table Processing:**
```python
# Extract all tables from a PDF
pdf_path = 'test_pdf/table_extraction_example.pdf'
table_results = extract_tables_from_pdf(pdf_path)

for result in table_results:
    print(f"Page {result['page_num'] + 1}, Table {result['table_index']}")
    print(f"Markdown:\n{result['table_markdown']}")
    print(f"Description: {result['context_augmented_table']}")
    print("-" * 50)
```

### 4. Multi-Modal Document Processing

For comprehensive document analysis, you can process text, images, and tables together:

```python
from document_process import process_pdf
from image_table import extract_images_from_pdf, extract_tables_from_pdf

def process_complete_pdf(pdf_path, es_index):
    """Process PDF with text, images, and tables"""
    
    # 1. Process text content
    print("Processing text content...")
    process_pdf(es_index, pdf_path)
    
    # 2. Extract and process images
    print("Processing images...")
    image_results = extract_images_from_pdf(pdf_path)
    print(f"Extracted {len(image_results)} images")
    
    # 3. Extract and process tables
    print("Processing tables...")
    table_results = extract_tables_from_pdf(pdf_path)
    print(f"Extracted {len(table_results)} tables")
    
    return {
        'images': image_results,
        'tables': table_results
    }

# Example usage
results = process_complete_pdf('test_pdf/image_extraction_example.pdf', 'multimodal_index')
```

### 5. Document Querying

The `retrieve_documents.py` module provides advanced querying capabilities:

```python
from retrieve_documents import elastic_search, rerank, rag_fusion, query_decompositon

# Basic search
query = "åˆ‘äº‹è¯‰è®¼æ³•çš„åŸºæœ¬åŸåˆ™æ˜¯ä»€ä¹ˆï¼Ÿ"
results = elastic_search(query, 'pdf_index')

# Enhanced search with reranking
reranked_results = rerank(query, results)

# Query decomposition for complex questions
sub_queries = query_decompositon("åˆ‘äº‹è¯‰è®¼æ³•å’Œæ°‘äº‹è¯‰è®¼æ³•çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ")

# RAG Fusion for multiple query variations
fusion_queries = rag_fusion("ä»€ä¹ˆæ˜¯æ— ç½ªæ¨å®šåŸåˆ™ï¼Ÿ")
```

### 3. Advanced Query Techniques

#### Hybrid Search
Combines keyword search and semantic search:
```python
# The system automatically performs:
# 1. Keyword search using jieba segmentation
# 2. Vector similarity search
# 3. Reciprocal Rank Fusion (RRF) to combine results
```

#### Query Enhancement
```python
# Query decomposition for complex questions
complex_query = "åˆ‘äº‹è¯‰è®¼æ³•å’Œæ°‘äº‹è¯‰è®¼æ³•çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ"
sub_queries = query_decompositon(complex_query)
# Returns: ["ä»€ä¹ˆæ˜¯åˆ‘äº‹è¯‰è®¼æ³•ï¼Ÿ", "ä»€ä¹ˆæ˜¯æ°‘äº‹è¯‰è®¼æ³•ï¼Ÿ", "åˆ‘äº‹è¯‰è®¼æ³•å’Œæ°‘äº‹è¯‰è®¼æ³•çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ"]

# RAG Fusion for better coverage
fusion_queries = rag_fusion("æ— ç½ªæ¨å®šåŸåˆ™")
# Returns: ["ä»€ä¹ˆæ˜¯æ— ç½ªæ¨å®šåŸåˆ™ï¼Ÿ", "æ— ç½ªæ¨å®šåŸåˆ™çš„æ³•å¾‹ä¾æ®æ˜¯ä»€ä¹ˆï¼Ÿ"]
```

#### Multi-turn Conversation
```python
# Coreference resolution for follow-up questions
chat_history = """
'user': ä»€ä¹ˆæ˜¯åˆ‘äº‹è¯‰è®¼æ³•ï¼Ÿ
'assistant': åˆ‘äº‹è¯‰è®¼æ³•æ˜¯è§„èŒƒåˆ‘äº‹è¯‰è®¼ç¨‹åºçš„æ³•å¾‹...
'user': å®ƒçš„åŸºæœ¬åŸåˆ™æœ‰å“ªäº›ï¼Ÿ
"""

resolved_query = coreference_resolution("å®ƒçš„åŸºæœ¬åŸåˆ™æœ‰å“ªäº›ï¼Ÿ", chat_history)
# Returns: "åˆ‘äº‹è¯‰è®¼æ³•çš„åŸºæœ¬åŸåˆ™æœ‰å“ªäº›ï¼Ÿ"
```

## ğŸ” Example Queries

### Text Content Queries (xingshisusongfa.pdf)
```python
queries = [
    "ä»€ä¹ˆæ˜¯åˆ‘äº‹è¯‰è®¼æ³•ï¼Ÿ",
    "åˆ‘äº‹è¯‰è®¼æ³•çš„åŸºæœ¬åŸåˆ™æœ‰å“ªäº›ï¼Ÿ",
    "ä»€ä¹ˆæ˜¯æ— ç½ªæ¨å®šåŸåˆ™ï¼Ÿ",
    "åˆ‘äº‹è¯‰è®¼ç¨‹åºåŒ…æ‹¬å“ªäº›é˜¶æ®µï¼Ÿ",
    "ä»€ä¹ˆæ˜¯è¯æ®çš„åˆæ³•æ€§ï¼Ÿ"
]
```

### Image Content Queries (image_extraction_example.pdf)
```python
queries = [
    "æ–‡æ¡£ä¸­æœ‰å“ªäº›å›¾ç‰‡ï¼Ÿ",
    "å›¾ç‰‡å±•ç¤ºäº†ä»€ä¹ˆå†…å®¹ï¼Ÿ",
    "å›¾ç‰‡ä¸­çš„æ–‡å­—æ˜¯ä»€ä¹ˆï¼Ÿ",
    "å›¾ç‰‡è¯´æ˜äº†ä»€ä¹ˆæ¦‚å¿µï¼Ÿ",
    "å›¾ç‰‡å’Œå‘¨å›´æ–‡å­—çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ"
]
```

### Table Content Queries (table_extraction_example.pdf)
```python
queries = [
    "æ–‡æ¡£ä¸­æœ‰å“ªäº›è¡¨æ ¼ï¼Ÿ",
    "è¡¨æ ¼æ˜¾ç¤ºäº†ä»€ä¹ˆæ•°æ®ï¼Ÿ",
    "è¡¨æ ¼çš„ç»“æ„æ˜¯ä»€ä¹ˆï¼Ÿ",
    "è¡¨æ ¼çš„ç”¨é€”æ˜¯ä»€ä¹ˆï¼Ÿ",
    "è¡¨æ ¼ä¸­çš„æ•°æ®è¯´æ˜äº†ä»€ä¹ˆï¼Ÿ"
]
```

### Multi-Modal Queries
```python
queries = [
    "æ–‡æ¡£ä¸­å›¾ç‰‡å’Œè¡¨æ ¼çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ",
    "å›¾ç‰‡å’Œæ–‡å­—å¦‚ä½•ç›¸äº’è¡¥å……ï¼Ÿ",
    "è¡¨æ ¼æ•°æ®å¦‚ä½•æ”¯æŒæ–‡æ¡£çš„ä¸»è¦è§‚ç‚¹ï¼Ÿ",
    "æ–‡æ¡£çš„è§†è§‰å…ƒç´ å¦‚ä½•å¢å¼ºç†è§£ï¼Ÿ"
]
```

### Comparative Queries
```python
queries = [
    "åˆ‘äº‹è¯‰è®¼æ³•å’Œæ°‘äº‹è¯‰è®¼æ³•çš„åŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
    "å…¬è¯‰æ¡ˆä»¶å’Œè‡ªè¯‰æ¡ˆä»¶æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ",
    "ä¸€å®¡ç¨‹åºå’ŒäºŒå®¡ç¨‹åºçš„åŒºåˆ«ï¼Ÿ"
]
```

### Specific Legal Concepts
```python
queries = [
    "ä»€ä¹ˆæ˜¯è¾©æŠ¤æƒï¼Ÿ",
    "çŠ¯ç½ªå«Œç–‘äººæœ‰å“ªäº›æƒåˆ©ï¼Ÿ",
    "ä»€ä¹ˆæ˜¯å¼ºåˆ¶æªæ–½ï¼Ÿ",
    "åˆ‘äº‹è¯‰è®¼ä¸­çš„è¯æ˜æ ‡å‡†æ˜¯ä»€ä¹ˆï¼Ÿ"
]
```

## ğŸ“Š Query Results Format

Each query returns results with the following structure:

```python
{
    'id': 'document_chunk_id',
    'text': 'extracted text content',
    'file_id': 'file_identifier',
    'metadata': {
        'file_name': 'xingshisusongfa.pdf',
        'page': 1,
        'chunk_id': 0
    },
    'rank': 1,
    'score': 0.95  # Relevance score (if reranked)
}
```

## ğŸ› ï¸ Configuration

### Elasticsearch Configuration
Edit `config.py` to match your Elasticsearch setup:

```python
class ElasticConfig:
    url = 'http://localhost:9200'  # Update with your credentials if needed

# Embedding service URLs
EMBEDDING_URL = "http://test.2brain.cn:9800/v1/emb"
RERANK_URL = "http://test.2brain.cn:2260/rerank"
```

### Text Processing Parameters
In `document_process.py`, you can adjust:

```python
# Chunk size and overlap
chunk_size = 1024        # Tokens per chunk
chunk_overlap = 100      # Overlap between chunks

# Batch size for embedding generation
batch_size = 25          # Process 25 chunks at a time
```

### Image Processing Parameters
In `image_table.py`, you can adjust:

```python
# Image filtering parameters
min_image_width = 200    # Minimum image width
min_image_height = 100   # Minimum image height
page_width_ratio = 3     # Image must be at least 1/3 of page width

# Vision model configuration
IMAGE_MODEL_URL = "http://test.2brain.cn:23333/v1"  # Vision model endpoint
model_name = "internvl-internlm2"                   # Vision model name
```

### Table Processing Parameters
In `image_table.py`, you can adjust:

```python
# Table extraction settings
table_detection_confidence = 0.8  # Confidence threshold for table detection
markdown_formatting = True        # Convert tables to Markdown
context_window = 1500            # Characters of context around tables
```

## ğŸ¯ Best Practices

### 1. Query Formulation
- Use specific legal terms when possible
- Ask focused questions rather than broad ones
- Use comparative language for differences ("åŒºåˆ«", "ä¸åŒ")
- Include context for ambiguous terms

### 2. Result Interpretation
- Check the relevance scores
- Look at multiple results for comprehensive answers
- Use reranking for better quality results
- Consider query decomposition for complex questions

### 3. Performance Optimization
- Use appropriate chunk sizes for your document type
- Batch embedding generation for efficiency
- Index multiple documents in the same index for cross-document queries

## ğŸ”§ Troubleshooting

### Common Issues

1. **Elasticsearch Connection Error**
   ```bash
   # Check if Elasticsearch is running
   curl -X GET "localhost:9200/"
   
   # Update credentials in config.py if needed
   ```

2. **Embedding Service Error**
   ```bash
   # Test embedding service
   python3 -c "from embedding import local_embedding; print(local_embedding(['test']))"
   ```

3. **PDF Processing Error**
   ```bash
   # Check if PDF file exists and is readable
   ls -la test_pdf/xingshisusongfa.pdf
   ```

### Performance Issues

1. **Slow Processing**
   - Reduce chunk size
   - Increase batch size
   - Use faster embedding models

2. **Memory Issues**
   - Process documents in smaller batches
   - Reduce chunk overlap
   - Clear Elasticsearch cache

## ğŸ“ˆ Advanced Features

### 1. Multi-Document Queries
```python
# Process multiple PDFs into the same index
pdf_files = [
    'test_pdf/xingshisusongfa.pdf',
    'test_pdf/table_extraction_example.pdf',
    'test_pdf/image_extraction_example.pdf'
]

for pdf_file in pdf_files:
    process_pdf('multi_doc_index', pdf_file)
```

### 2. Metadata Filtering
```python
# Query with metadata filters
query = {
    "bool": {
        "must": [
            {"match": {"text": "åˆ‘äº‹è¯‰è®¼æ³•"}},
            {"term": {"metadata.file_name": "xingshisusongfa.pdf"}}
        ]
    }
}
```

### 3. Custom Scoring
```python
# Adjust RRF parameters
def hybrid_search_rrf(keyword_hits, vector_hits, k=60):
    # k=60 is the RRF parameter, adjust for your needs
    # Lower k gives more weight to top results
```

## ğŸ‰ Example Complete Workflow

### Text-Only Workflow
```python
#!/usr/bin/env python3
"""
Complete PDF Text Query Workflow Example
"""

from es_functions import create_elastic_index
from document_process import process_pdf
from retrieve_documents import elastic_search, rerank

def main():
    # 1. Create index
    index_name = 'legal_docs'
    create_elastic_index(index_name)
    
    # 2. Process PDF
    pdf_file = 'test_pdf/xingshisusongfa.pdf'
    process_pdf(index_name, pdf_file)
    
    # 3. Query examples
    queries = [
        "ä»€ä¹ˆæ˜¯åˆ‘äº‹è¯‰è®¼æ³•ï¼Ÿ",
        "åˆ‘äº‹è¯‰è®¼æ³•çš„åŸºæœ¬åŸåˆ™æœ‰å“ªäº›ï¼Ÿ",
        "ä»€ä¹ˆæ˜¯æ— ç½ªæ¨å®šåŸåˆ™ï¼Ÿ"
    ]
    
    for query in queries:
        print(f"\nğŸ” Query: {query}")
        print("-" * 50)
        
        # Search
        results = elastic_search(query, index_name)
        
        # Rerank for better results
        reranked_results = rerank(query, results)
        
        # Display top results
        for i, result in enumerate(reranked_results[:3]):
            print(f"{i+1}. {result['text'][:200]}...")
            print(f"   Score: {result.get('score', 'N/A')}")
            print()

if __name__ == "__main__":
    main()
```

### Multi-Modal Workflow (Text + Images + Tables)
```python
#!/usr/bin/env python3
"""
Complete Multi-Modal PDF Query Workflow Example
"""

from es_functions import create_elastic_index
from document_process import process_pdf
from image_table import extract_images_from_pdf, extract_tables_from_pdf
from retrieve_documents import elastic_search, rerank

def process_multimodal_pdf(pdf_path, index_name):
    """Process PDF with all modalities"""
    
    print(f"ğŸ”„ Processing: {pdf_path}")
    print("=" * 60)
    
    # 1. Process text content
    print("ğŸ“„ Processing text content...")
    process_pdf(index_name, pdf_path)
    print("âœ… Text processing completed")
    
    # 2. Extract and process images
    print("\nğŸ–¼ï¸ Processing images...")
    try:
        image_results = extract_images_from_pdf(pdf_path)
        print(f"âœ… Extracted {len(image_results)} images")
        
        for i, result in enumerate(image_results[:3]):  # Show first 3
            print(f"   Image {i+1}: Page {result['page_num']+1}")
            print(f"   Description: {result['summary'][:100]}...")
    except Exception as e:
        print(f"âš ï¸ Image processing failed: {e}")
        image_results = []
    
    # 3. Extract and process tables
    print("\nğŸ“Š Processing tables...")
    try:
        table_results = extract_tables_from_pdf(pdf_path)
        print(f"âœ… Extracted {len(table_results)} tables")
        
        for i, result in enumerate(table_results[:3]):  # Show first 3
            print(f"   Table {i+1}: Page {result['page_num']+1}")
            print(f"   Description: {result['context_augmented_table'][:100]}...")
    except Exception as e:
        print(f"âš ï¸ Table processing failed: {e}")
        table_results = []
    
    return {
        'images': image_results,
        'tables': table_results
    }

def query_multimodal_content(index_name, queries):
    """Query multimodal content"""
    
    print(f"\nğŸ” Querying multimodal content...")
    print("=" * 60)
    
    for query in queries:
        print(f"\nğŸ¯ Query: {query}")
        print("-" * 50)
        
        # Search
        results = elastic_search(query, index_name)
        
        # Rerank for better results
        reranked_results = rerank(query, results)
        
        # Display top results
        for i, result in enumerate(reranked_results[:3]):
            print(f"{i+1}. {result['text'][:200]}...")
            print(f"   Score: {result.get('score', 'N/A')}")
            print()

def main():
    # 1. Create index
    index_name = 'multimodal_docs'
    create_elastic_index(index_name)
    
    # 2. Process different PDF types
    pdf_files = [
        'test_pdf/xingshisusongfa.pdf',           # Text-heavy legal document
        'test_pdf/image_extraction_example.pdf',  # Image-rich document
        'test_pdf/table_extraction_example.pdf'   # Table-rich document
    ]
    
    all_results = {}
    
    for pdf_file in pdf_files:
        try:
            results = process_multimodal_pdf(pdf_file, index_name)
            all_results[pdf_file] = results
        except Exception as e:
            print(f"âŒ Failed to process {pdf_file}: {e}")
    
    # 3. Query examples for different content types
    text_queries = [
        "ä»€ä¹ˆæ˜¯åˆ‘äº‹è¯‰è®¼æ³•ï¼Ÿ",
        "åˆ‘äº‹è¯‰è®¼æ³•çš„åŸºæœ¬åŸåˆ™æœ‰å“ªäº›ï¼Ÿ"
    ]
    
    image_queries = [
        "æ–‡æ¡£ä¸­æœ‰å“ªäº›å›¾ç‰‡ï¼Ÿ",
        "å›¾ç‰‡å±•ç¤ºäº†ä»€ä¹ˆå†…å®¹ï¼Ÿ"
    ]
    
    table_queries = [
        "æ–‡æ¡£ä¸­æœ‰å“ªäº›è¡¨æ ¼ï¼Ÿ",
        "è¡¨æ ¼æ˜¾ç¤ºäº†ä»€ä¹ˆæ•°æ®ï¼Ÿ"
    ]
    
    multimodal_queries = [
        "æ–‡æ¡£ä¸­å›¾ç‰‡å’Œè¡¨æ ¼çš„å…³ç³»æ˜¯ä»€ä¹ˆï¼Ÿ",
        "å›¾ç‰‡å’Œæ–‡å­—å¦‚ä½•ç›¸äº’è¡¥å……ï¼Ÿ"
    ]
    
    # 4. Run queries
    print(f"\nğŸ“ Text Content Queries:")
    query_multimodal_content(index_name, text_queries)
    
    print(f"\nğŸ–¼ï¸ Image Content Queries:")
    query_multimodal_content(index_name, image_queries)
    
    print(f"\nğŸ“Š Table Content Queries:")
    query_multimodal_content(index_name, table_queries)
    
    print(f"\nğŸ”— Multi-Modal Queries:")
    query_multimodal_content(index_name, multimodal_queries)
    
    # 5. Summary
    print(f"\nğŸ“ˆ Processing Summary:")
    print("=" * 60)
    for pdf_file, results in all_results.items():
        print(f"ğŸ“„ {pdf_file}:")
        print(f"   Images: {len(results['images'])}")
        print(f"   Tables: {len(results['tables'])}")

if __name__ == "__main__":
    main()
```

## ğŸ“š Additional Resources

### Core Technologies
- **RAG Framework**: Based on the Retrieval Augmented Generation pattern
- **Elasticsearch**: Vector database for document storage and retrieval
- **PyMuPDF**: PDF text extraction and processing
- **Jieba**: Chinese text segmentation for keyword search
- **OpenAI Embeddings**: Semantic vector generation

### Multi-Modal Technologies
- **Vision Models**: Image analysis and description generation
- **Table Detection**: Automatic table identification and extraction
- **Context Augmentation**: Enhanced descriptions using surrounding text
- **Markdown Conversion**: Structured table representation

### Processing Capabilities
- **Text**: Direct extraction, chunking, and embedding
- **Images**: Visual analysis, OCR, context-aware descriptions
- **Tables**: Structure detection, data extraction, natural language descriptions
- **Multi-Modal**: Cross-modal relationship analysis and querying

## ğŸ¤ Contributing

To extend the PDF query system:

### Text Processing
1. Add new document types in `document_process.py`
2. Implement custom chunking strategies
3. Add domain-specific query enhancement
4. Integrate additional embedding models
5. Implement custom reranking algorithms

### Multi-Modal Processing
1. Add support for more image formats
2. Implement custom vision models
3. Add advanced table analysis features
4. Implement cross-modal relationship detection
5. Add support for mathematical formulas and equations

### Advanced Features
1. Implement document summarization
2. Add citation and reference tracking
3. Implement document comparison
4. Add temporal analysis for document versions
5. Implement collaborative filtering for similar documents

---

**Ready to query your PDF documents with the power of multi-modal RAG!** ğŸš€ğŸ“„ğŸ–¼ï¸ğŸ“Š
